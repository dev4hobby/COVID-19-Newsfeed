# COVID-19-newsfeed

This is Crawler.
but service result as static page.

---

1. `Crawler` written in `Python` brings disaster news every 20 minutes.
2. Save the imported data in `json` format.
3. Static page deployed as `Gatsby` fetches `json` file
> Gatsby supports react component.
> Static pages are distributed in the [gh-pages](https://github.com/dev4hobby/COVID-19-newsfeed/tree/gh-pages) branch.

Check this out
- [crawler](https://github.com/dev4hobby/COVID-19-newsfeed/blob/master/run.py)
- [web client](https://github.com/dev4hobby/COVID-19-newsfeed/tree/master/web_client)
- [json file](https://raw.githubusercontent.com/dev4hobby/COVID-19-newsfeed/master/feed.json)
- [result page](https://dev4hobby.github.io/COVID-19-newsfeed/)
